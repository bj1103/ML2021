{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML-HW6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8xb890XNpyp"
      },
      "source": [
        "!pip install stylegan2-pytorch==1.8.1\n",
        "!pip install pytorch-fid\n",
        "!stylegan2_pytorch  --data ./faces/ --image-size 64 --batch-size 16  --num_workers 2  --gradient_accumulate_every=2 --calculate-fid-every 500 --top-k-training --attn-layers [1,2,3,4,5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBhLv7vHNlQb"
      },
      "source": [
        "import torch\n",
        "from torchvision.utils import save_image\n",
        "from stylegan2_pytorch import ModelLoader, Trainer\n",
        "\n",
        "class newLoader(ModelLoader):\n",
        "    def __init__(self, model_dir, load_from = -1):\n",
        "        self.model = Trainer(models_dir = model_dir, image_size=64, attn_layers=[1,2,3,4,5])\n",
        "        self.model.load(load_from)\n",
        "\n",
        "model = newLoader('./models/', 25)\n",
        "\n",
        "for i in range(500):\n",
        "    noise = torch.randn(1, 512).cuda()\n",
        "    styles = model.noise_to_styles(noise, trunc_psi = 0.7)\n",
        "    images = model.styles_to_images(styles)\n",
        "    save_image(images, f'./output/{i}.jpg')\n",
        "\n",
        "model = newLoader('./models/', 27)\n",
        "\n",
        "for i in range(500, 1000):\n",
        "    noise = torch.randn(1, 512).cuda()\n",
        "    styles = model.noise_to_styles(noise, trunc_psi = 0.7)\n",
        "    images = model.styles_to_images(styles)\n",
        "    save_image(images, f'./output/{i}.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}